{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq9BgIsZy2ZJ",
        "outputId": "45a02f94-4845-4ba0-e37a-80fa58222f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (4.0.1)\n",
            "Requirement already satisfied: py4j==0.10.9.9 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.9)\n"
          ]
        }
      ],
      "source": [
        "#installing pyspark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing sparksession\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        ".appName(\"AmazonReviewsBigData\") \\\n",
        ".getOrCreate()"
      ],
      "metadata": {
        "id": "gHCTLwPJzcOZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Dataset\n",
        "df = spark.read.csv(\"/content/drive/MyDrive/Reviews.csv\", header=True, inferSchema=True)\n",
        "df.printSchema()\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idq3gjK3zvta",
        "outputId": "499aa6bc-6a2a-4c78-a8e9-7735096a56c9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Id: integer (nullable = true)\n",
            " |-- ProductId: string (nullable = true)\n",
            " |-- UserId: string (nullable = true)\n",
            " |-- ProfileName: string (nullable = true)\n",
            " |-- HelpfulnessNumerator: string (nullable = true)\n",
            " |-- HelpfulnessDenominator: string (nullable = true)\n",
            " |-- Score: string (nullable = true)\n",
            " |-- Time: string (nullable = true)\n",
            " |-- Summary: string (nullable = true)\n",
            " |-- Text: string (nullable = true)\n",
            "\n",
            "+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
            "| Id| ProductId|        UserId|         ProfileName|HelpfulnessNumerator|HelpfulnessDenominator|Score|      Time|             Summary|                Text|\n",
            "+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
            "|  1|B001E4KFG0|A3SGXH7AUHU8GW|          delmartian|                   1|                     1|    5|1303862400|Good Quality Dog ...|I have bought sev...|\n",
            "|  2|B00813GRG4|A1D87F6ZCVE5NK|              dll pa|                   0|                     0|    1|1346976000|   Not as Advertised|\"Product arrived ...|\n",
            "|  3|B000LQOCH0| ABXLMWJIXXAIN|\"Natalia Corres \"...|                   1|                     1|    4|1219017600|\"\"\"Delight\"\" says...|\"This is a confec...|\n",
            "|  4|B000UA0QIQ|A395BORC6FGVXV|                Karl|                   3|                     3|    2|1307923200|      Cough Medicine|If you are lookin...|\n",
            "|  5|B006K2ZZ7K|A1UQRSCLF8GW1T|\"Michael D. Bigha...|                   0|                     0|    5|1350777600|         Great taffy|Great taffy at a ...|\n",
            "+---+----------+--------------+--------------------+--------------------+----------------------+-----+----------+--------------------+--------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "\n",
        "# Remove rows with null critical values\n",
        "clean_df = df.dropna(subset=[\"ProductId\", \"UserId\", \"Score\", \"Time\"])"
      ],
      "metadata": {
        "id": "EdInyCuW0Cpr"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#convert unix time into time\n",
        "from pyspark.sql.functions import from_unixtime, year\n",
        "\n",
        "\n",
        "clean_df = clean_df.withColumn(\"review_date\", from_unixtime(col(\"Time\")))\n",
        "clean_df = clean_df.withColumn(\"year\", year(col(\"review_date\")))\n",
        "\n",
        "\n",
        "clean_df.select(\"Time\", \"review_date\", \"year\").show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpYOvA5z0afu",
        "outputId": "600c1766-49f9-4334-84bd-e2a281166230"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------------+----+\n",
            "|      Time|        review_date|year|\n",
            "+----------+-------------------+----+\n",
            "|1303862400|2011-04-27 00:00:00|2011|\n",
            "|1346976000|2012-09-07 00:00:00|2012|\n",
            "|1219017600|2008-08-18 00:00:00|2008|\n",
            "|1307923200|2011-06-13 00:00:00|2011|\n",
            "|1350777600|2012-10-21 00:00:00|2012|\n",
            "+----------+-------------------+----+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysis 1: Rating Distribution\n",
        "rating_dist = clean_df.groupBy(\"Score\").count().orderBy(\"Score\")\n",
        "rating_dist.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4nvETaC2_pF",
        "outputId": "6b097c12-6603-499c-b23a-27f853e4b419"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----+\n",
            "|         Score|count|\n",
            "+--------------+-----+\n",
            "|          ...\"|   23|\n",
            "|     Author\"\"\"|    3|\n",
            "|   Comp sci\"\"\"|    1|\n",
            "|     Critic\"\"\"|    1|\n",
            "|        Dad\"\"\"|    1|\n",
            "|     Dance...\"|    4|\n",
            "|        Design|    1|\n",
            "|        Ed...\"|    1|\n",
            "|       Hugs\"\"\"|    1|\n",
            "|     Lyme ...\"|    1|\n",
            "|     Medit...\"|    2|\n",
            "|        Moscow|    1|\n",
            "| Music Fan...\"|    8|\n",
            "|         RN\"\"\"|   23|\n",
            "|        Sm...\"|    1|\n",
            "|      USA ...\"|    1|\n",
            "|   Video Games|    1|\n",
            "|         a...\"|   10|\n",
            "|     and F...\"|    1|\n",
            "| and Kitten\"\"\"|  104|\n",
            "+--------------+-----+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysis 2: Top 10 Products by Number of Reviews\n",
        "top_products = clean_df.groupBy(\"ProductId\") \\\n",
        ".count() \\\n",
        ".orderBy(col(\"count\").desc()) \\\n",
        ".limit(10)\n",
        "\n",
        "\n",
        "top_products.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWRuw2N33NVy",
        "outputId": "c18cc146-7b35-4e39-b959-1f8b86977458"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "| ProductId|count|\n",
            "+----------+-----+\n",
            "|B007JFMH8M|  913|\n",
            "|B0026RQTGE|  632|\n",
            "|B002QWP89S|  632|\n",
            "|B002QWHJOU|  632|\n",
            "|B002QWP8H0|  632|\n",
            "|B003B3OOPA|  623|\n",
            "|B001EO5Q64|  567|\n",
            "|B0013NUGDE|  564|\n",
            "|B007M832YY|  564|\n",
            "|B0026KNQSA|  564|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysis 3: Helpfulness Ratio\n",
        "from pyspark.sql.functions import when, col\n",
        "\n",
        "help_df = clean_df.withColumn(\n",
        "    \"helpfulness_ratio\",\n",
        "    when(\n",
        "        col(\"HelpfulnessDenominator\").cast(\"int\") > 0,\n",
        "        col(\"HelpfulnessNumerator\").cast(\"double\") /\n",
        "        col(\"HelpfulnessDenominator\").cast(\"double\")\n",
        "    ).otherwise(0.0)\n",
        ")\n",
        "\n",
        "help_df.select(\"Score\", \"helpfulness_ratio\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrB5Og624D6n",
        "outputId": "17547178-cb46-431f-f838-437f33e0035f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------+\n",
            "|Score|helpfulness_ratio|\n",
            "+-----+-----------------+\n",
            "|    5|              1.0|\n",
            "|    1|              0.0|\n",
            "|    4|              1.0|\n",
            "|    2|              1.0|\n",
            "|    5|              0.0|\n",
            "+-----+-----------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysis 4: Most Helpful Reviews\n",
        "from pyspark.sql.functions import col, when, expr\n",
        "\n",
        "help_df = clean_df.withColumn(\n",
        "    \"helpfulness_ratio\",\n",
        "    when(\n",
        "        expr(\"try_cast(HelpfulnessDenominator as double)\") > 0,\n",
        "        expr(\"try_cast(HelpfulnessNumerator as double)\") /\n",
        "        expr(\"try_cast(HelpfulnessDenominator as double)\")\n",
        "    ).otherwise(0.0)\n",
        ")\n"
      ],
      "metadata": {
        "id": "5mREHgjv4nzu"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Analysis 5: Reviews Over Time (Date-wise â€“ Only DMY)\n",
        "from pyspark.sql.functions import col, from_unixtime, to_date, expr\n",
        "\n",
        "clean_df = clean_df.withColumn(\n",
        "    \"review_dmy\",\n",
        "    to_date(from_unixtime(expr(\"try_cast(Time as long)\")))\n",
        ")\n",
        "\n",
        "# Date-wise review count\n",
        "datewise_reviews = clean_df.groupBy(\"review_dmy\") \\\n",
        "    .count() \\\n",
        "    .orderBy(\"review_dmy\")\n",
        "\n",
        "datewise_reviews.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1K-Yp2gq5Hae",
        "outputId": "7d352179-9c34-49b2-fa11-7b89c69f8a75"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+\n",
            "|review_dmy|count|\n",
            "+----------+-----+\n",
            "|      NULL|    8|\n",
            "|1970-01-01| 2738|\n",
            "|1999-10-08|    1|\n",
            "|1999-10-25|    1|\n",
            "|1999-12-02|    1|\n",
            "|1999-12-06|    3|\n",
            "|2000-01-03|    1|\n",
            "|2000-01-09|    3|\n",
            "|2000-01-19|    3|\n",
            "|2000-01-24|    1|\n",
            "|2000-02-26|    3|\n",
            "|2000-06-03|    3|\n",
            "|2000-06-23|    1|\n",
            "|2000-06-29|    1|\n",
            "|2000-07-31|    1|\n",
            "|2000-08-09|    2|\n",
            "|2000-08-15|    3|\n",
            "|2000-10-03|    3|\n",
            "|2000-12-05|    1|\n",
            "|2000-12-19|    3|\n",
            "+----------+-----+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    }
  ]
}